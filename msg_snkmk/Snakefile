"""
Author: Y. Ahmed-Braimah
--- Snakemake workflow for PacBio genome annotation
--- and genomic analysis
"""

import json
import os
from os.path import join, basename, dirname, isfile
from os import getcwd, listdir
from subprocess import check_output
import subprocess

##--------------------------------------------------------------------------------------##
## Functions
##--------------------------------------------------------------------------------------##

# To print process messages
def message(x):
  print()

# To remove suffix from a string
def rstrip(text, suffix):
    if not text.endswith(suffix):
        return text
    return text[:len(text)-len(suffix)]

## define environment variables

##--------------------------------------------------------------------------------------##
## Global config files:
##--------------------------------------------------------------------------------------##

configfile: 'config.yml'

# Full path to an uncompressed FASTA file with all chromosome sequences.
PARENT_1_DNA = config['PARENT_1_DNA']
PARENT_2_DNA = config['PARENT_2_DNA']

# Full path to a folder where final output files will be deposited.
OUT_DIR = config['OUT_DIR']
BASE_MSG = config['BASE_MSG']
SCRIPTS_DIR = config['SCRIPTS_DIR']
PHENO_FILE = config['PHENO_FILE']
SAMTOOLS_PATH = config['SAMTOOLS_PATH']


FILES = json.load(open(config['PE_DNA_SAMPLES_JSON']))
SAMPLES = sorted(FILES.keys())


## Create the final output directory if it doesn't already exist
if not os.path.exists(OUT_DIR):
            os.makedirs(OUT_DIR)

##--------------------------------------------------------------------------------------##--------------------------------------------------------------------------------------
# _____ _             _               _               _
#|  ___(_)_ __   __ _| |   ___  _   _| |_ _ __  _   _| |_ ___
#| |_  | | '_ \ / _` | |  / _ \| | | | __| '_ \| | | | __/ __|
#|  _| | | | | | (_| | | | (_) | |_| | |_| |_) | |_| | |_\__ \
#|_|   |_|_| |_|\__,_|_|  \___/ \__,_|\__| .__/ \__,_|\__|___/
#                                        |_|
##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------

## Final expected output(s)
rule all:
    input:
        join(OUT_DIR, 'MultiQC', 'multiqc_report.html'),
        join(OUT_DIR, 'ancestry_data', 'ancestry-probs-par2.tsv.sorted.pulled.converted.thinned')

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##
# ______        ___
#| __ ) \      / / \
#|  _ \\ \ /\ / / _ \
#| |_) |\ V  V / ___ \
#|____/  \_/\_/_/   \_\
#
##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule for mapping PE reads to the genome with Bowtie2
rule INDEXES:
    input:
        p1 = PARENT_1_DNA,
        p2 = PARENT_2_DNA
    output:
        i1 = join(PARENT_1_DNA + '.ann'),
        i2 = join(PARENT_2_DNA + '.ann'),
    log:
        bwa = join(OUT_DIR, 'Logs', 'bwa_index.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'bwa_index.benchmark.tsv')
    message:
        """--- Making BWA indexes for parental genomes."""
    threads:
        8
    resources:
        mem_mb=32000
    conda:
        'envs/msg.yml'
    shell:
        'bwa index {input.p1} && bwa index {input.p2} 2> {log.bwa}'


##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule fastqc1:
    input:
        r1 = lambda wildcards: FILES[wildcards.sample]['R1'],
        r2 = lambda wildcards: FILES[wildcards.sample]['R2'],
    output:
        r1 = join(OUT_DIR, 'fastQC', '{sample}.R1_fastqc.html'),
        r2 = join(OUT_DIR, 'fastQC', '{sample}.R2_fastqc.html'),
    log:
        join(OUT_DIR, 'Logs', 'fastQC', '{sample}.fastQC.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'fastQC', '{sample}.fastQC.benchmark.tsv')
    message:
        """--- Checking read quality of sample "{wildcards.sample}" with FastQC """
    conda:
        'envs/DaGRP.yml'
    shell:
        'fastqc'
            ' -o ' + join(OUT_DIR, 'fastQC') +
            ' -t 4'
            ' -q'
            ' {input.r1} {input.r2}'
            ' > {log} 2>&1'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##
rule cutADAPT:
    input:
        r1 = lambda wildcards: FILES[wildcards.sample]['R1'],
        r2 = lambda wildcards: FILES[wildcards.sample]['R2']
    output:
        fastq1 = join(OUT_DIR, 'trimmed_reads', '{sample}.R1.fastq.gz'),
        fastq2 = join(OUT_DIR, 'trimmed_reads', '{sample}.R2.fastq.gz'),
        qc = join(OUT_DIR, 'trimmed_reads', '{sample}.qc.txt')
    params:
        # https://cutadapt.readthedocs.io/en/stable/guide.html#adapter-types
        adapters="-a CTGTCTCTTATACACATCT -A CTGTCTCTTATACACATCT",
        # https://cutadapt.readthedocs.io/en/stable/guide.html#
        extra="--minimum-length 30 -q 20"
    log:
        join(OUT_DIR, 'Logs', 'cutadapt', '{sample}.cutadapt.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'cutadapt', '{sample}.cutadapt.benchmark.tsv')
    message:
        """--- Trimming adaptors for sample {wildcards.sample}."""
    threads:
        4
    resources:
        mem_mb=8000
    wrapper:
        "v3.10.2/bio/cutadapt/pe"

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule fastqc2:
    input:
        fastq1 = join(OUT_DIR, 'trimmed_reads', '{sample}.R1.fastq.gz'),
        fastq2 = join(OUT_DIR, 'trimmed_reads', '{sample}.R2.fastq.gz'),
    output:
        r1 = join(OUT_DIR, 'fastQC_trim', '{sample}.R1_fastqc.html'),
        r2 = join(OUT_DIR, 'fastQC_trim', '{sample}.R2_fastqc.html'),
    log:
        join(OUT_DIR, 'Logs', 'fastQC_trim', '{sample}.fastQC.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'fastQC_trim', '{sample}.fastQC.benchmark.tsv')
    message:
        """--- Checking read quality of trimmed sample "{wildcards.sample}" with FastQC """
    conda:
        'envs/DaGRP.yml'
    shell:
        'fastqc'
            ' -o ' + join(OUT_DIR, 'fastQC_trim') +
            ' -t 4'
            ' -q'
            ' {input.fastq1} {input.fastq2}'
            ' > {log} 2>&1'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule catReads:
    input:
        r1 = join(OUT_DIR, 'trimmed_reads', '{sample}.R1.fastq.gz'),
        r2 = join(OUT_DIR, 'trimmed_reads', '{sample}.R2.fastq.gz')
    output:
        join(OUT_DIR, 'combined_reads', '{sample}.fastq.gz')
    message:
        """--- Combining paired reads for {wildcards.sample}."""
    threads:
        4
    resources:
        mem_mb=16000
    run:
        shell('zcat {input.r1} {input.r2} | sed "'"/^@/ s/ /:/g"'" | gzip - > {output}')

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

# rule count_reads:
#     input:
#          join(OUT_DIR, 'combined_reads', '{sample}.fastq.gz')
#     output:
#          join(OUT_DIR, 'read_counts', '{sample}.txt')
#     shell:
#         """
#         zcat {input} | echo $((`wc -l`/4)) > {output}
#         """
        
##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

# rule filter_samples:
#     input:
#         join(OUT_DIR, 'read_counts', '{sample}.txt')
#     output:
#         join(OUT_DIR, 'filtered', '{sample}.flag')
#     params:
#         threshold = config['READ_THRESHOLD']
#     shell:
#         """
#         if [ $(cat {input}) -ge {params.threshold} ]; then
#             touch {output};
#         else
#             rm -f {output};
#         fi
#         """

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule for mapping PE reads to the genome with Bowtie2
rule BWAp1:
    input:
        reads = join(OUT_DIR, 'combined_reads', '{sample}.fastq.gz'),
        # flag = join(OUT_DIR, 'filtered', '{sample}.flag'),
        index = PARENT_1_DNA,
        i1 = join(PARENT_1_DNA + '.ann')
    output:
        sai = join(OUT_DIR, 'sai_dir', 'aln_{sample}_par1.sai'),
        sam = join(OUT_DIR, 'sam_dir', 'aln_{sample}_par1.sam')
    log:
        sai = join(OUT_DIR, 'Logs', '{sample}', 'bwa_sai.log'),
        sam = join(OUT_DIR, 'Logs', '{sample}', 'bwa_sam.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'BWA_p1', '{sample}', 'benchmark.tsv')
    message:
        """--- Mapping sample "{wildcards.sample}" with BWA to parent1."""
    threads:
        8
    resources:
        mem_mb=32000
    conda:
        'envs/msg.yml'
    shell:
        'bwa aln'
                ' -t 8'
                ' -f {output.sai}'
                ' {input.index}'
                ' {input.reads}'
                ' > {log.sai} 2>&1 && '
        'bwa samse'
                # ' -t 8'
                ' -f {output.sam}'
                ' {input.index}'
                ' {output.sai}'
                ' {input.reads}'
                ' > {log.sam} 2>&1'


##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule for mapping PE reads to the genome with Bowtie2
rule BWAp2:
    input:
        reads = join(OUT_DIR, 'combined_reads', '{sample}.fastq.gz'),
        # flag = join(OUT_DIR, 'filtered', '{sample}.flag'), 
        index = PARENT_2_DNA,
        i2 = join(PARENT_2_DNA + '.ann')
    output:
        sai = join(OUT_DIR, 'sai_dir', 'aln_{sample}_par2.sai'),
        sam = join(OUT_DIR, 'sam_dir', 'aln_{sample}_par2.sam')
    log:
        sai = join(OUT_DIR, 'Logs', '{sample}', 'bwa_sai.log'),
        sam = join(OUT_DIR, 'Logs', '{sample}', 'bwa_sam.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'BWA_p2', '{sample}', 'benchmark.tsv')
    message:
        """--- Mapping sample "{wildcards.sample}" with BWA to parent2."""
    threads:
        8
    resources:
        mem_mb=32000
    conda:
        'envs/msg.yml'
    shell:
        'bwa aln'
                ' -t 8'
                ' -f {output.sai}'
                ' {input.index}'
                ' {input.reads}'
                ' > {log.sai} 2>&1 && '
        'bwa samse'
                # ' -t 8'
                ' -f {output.sam}'
                ' {input.index}'
                ' {output.sai}'
                ' {input.reads}'
                ' > {log.sam} 2>&1'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule for mapping PE reads to the genome with Bowtie2
# rule msg_symlink:
#     output:
#         msg = join(OUT_DIR, 'msg', 'msg', 'msg.pl')
#     message:
#         """--- Creating MSG directory symlink."""
#     run:
#         shell("""
#             if [ -L {OUT_DIR}/msg ]; then
#                 rm {OUT_DIR}/msg
#             fi
#             ln -s {BASE_MSG} {OUT_DIR}/msg
#         """)

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule for mapping PE reads to the genome with Bowtie2
rule extractRefAllele:
    input:
        sam_p1 = join(OUT_DIR, 'sam_dir', 'aln_{sample}_par1.sam'),
        sam_p2 = join(OUT_DIR, 'sam_dir', 'aln_{sample}_par2.sam')
        # msg = join(OUT_DIR, 'msg', 'msg', 'msg.pl')
    params:
        par1 = PARENT_1_DNA,
        par2 = PARENT_2_DNA,
        samtools = SAMTOOLS_PATH
    output:
        sam1 = join(OUT_DIR, 'hmm_data', '{sample}', 'aln_{sample}_par1-filtered.sam'),
        sam2 = join(OUT_DIR, 'hmm_data', '{sample}', 'aln_{sample}_par2-filtered.sam')
    log:
        join(OUT_DIR, 'Logs', '{sample}', 'extract_ref_allele.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', '{sample}', 'extract_ref_allele_benchmark.tsv')
    message:
        """--- Extracting reference alleles for sample "{wildcards.sample}" ."""
    threads:
        8
    resources:
        mem_mb=32000
    run:
        shell('bash ' + join(SCRIPTS_DIR, 'run_extract_ref_allele.sh') +
                ' -s ' + join(OUT_DIR, 'sam_dir') +
                ' -o ' + join(OUT_DIR, 'hmm_data') +
                ' -p {params.par1}'
                ' -q {params.par2}'
                ' -i {wildcards.sample}'
                ' -c all'
                ' -w aln'
                ' -k 6'
                ' -S {params.samtools}'
                ' -m ' + join(BASE_MSG) +
                ' > {log} 2>&1')


##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule for mapping PE reads to the genome with Bowtie2
rule makePileups:
    input:
        sam1 = join(OUT_DIR, 'hmm_data', '{sample}', 'aln_{sample}_par1-filtered.sam'),
        sam2 = join(OUT_DIR, 'hmm_data', '{sample}', 'aln_{sample}_par2-filtered.sam')
    params:
        par1 = PARENT_1_DNA,
        par2 = PARENT_2_DNA,
        samtools = SAMTOOLS_PATH
    output:
        sam1 = join(OUT_DIR, 'hmm_data', '{sample}', 'aln_{sample}_par1-filtered-sorted.bam')
    log:
        join(OUT_DIR, 'Logs', '{sample}', 'make_pileups.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', '{sample}', 'make_pileups_benchmark.tsv')
    message:
        """--- Making pileups for sample "{wildcards.sample}" ."""
    threads:
        8
    resources:
        mem_mb=32000
    # conda:
    #     'envs/samtool_0.1.9.yml'
    shell:
        'bash ' + join(SCRIPTS_DIR, 'run_make_pileups.sh') +
                ' -o ' + join(OUT_DIR, 'hmm_data') +
                ' -p {params.par1}'
                ' -q {params.par2}'
                ' -i {wildcards.sample}'
                ' -S {params.samtools}'
                ' -m ' + join(BASE_MSG) +
                ' > {log} 2>&1'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule for mapping PE reads to the genome with Bowtie2
rule qualiMap:
    input:
        bam = join(OUT_DIR, 'hmm_data', '{sample}', 'aln_{sample}_par1-filtered-sorted.bam')
    output:
        bamqc = join(OUT_DIR, 'bamqc', '{sample}', 'qualimapReport.html')
    log:
        join(OUT_DIR, 'Logs', '{sample}', 'bamqc.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', '{sample}', 'bamqc_benchmark.tsv')
    message:
        """--- running BAM QC for "{wildcards.sample}" ."""
    threads:
        8
    resources:
        mem_mb=32000
    conda:
        'envs/DaGRP.yml'
    shell:
        'qualimap bamqc'
            ' -bam {input.bam}'
            ' -c'
            ' -outdir ' + join(OUT_DIR, 'bamqc', '{wildcards.sample}') +
            ' --java-mem-size=32G'
            ' -nt 8'
            ' > {log} 2>&1'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule for mapping PE reads to the genome with Bowtie2
rule writeHMM:
    input:
        sam1 = join(OUT_DIR, 'hmm_data', '{sample}', 'aln_{sample}_par1-filtered-sorted.bam'),
        reference = PARENT_1_DNA
    output:
        done = join(OUT_DIR, 'hmm_data', '{sample}', 'hmm.ok')
    log:
        join(OUT_DIR, 'Logs', '{sample}', 'write_hmm_data.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', '{sample}', 'write_hmm_data_benchmark.tsv')
    message:
        """--- Writing HMM data for sample "{wildcards.sample}" ."""
    threads:
        8
    resources:
        mem_mb=32000
    run:
        shell('bash ' + join(SCRIPTS_DIR, 'run_write_hmm_data.sh') +
                ' -o ' + join(OUT_DIR, 'hmm_data') +
                ' -i {wildcards.sample}'
                ' -m ' + join(BASE_MSG) +
                ' -c all'
                ' > {log} 2>&1')
        # Check that all expected output files are present
        chrom_files = []
        with open(input.reference, 'r') as ref:
            for line in ref:
                if line.startswith('>'):
                    chrom = line[1:].strip().split()[0]
                    chrom_file = join(OUT_DIR, 'hmm_data', f'{wildcards.sample}', f'{wildcards.sample}-{chrom}.hmmdata').replace(" ", "")
                    chrom_files.append(chrom_file)

        missing_files = [f for f in chrom_files if not os.path.exists(f)]
        if missing_files:
            raise Exception(f"Missing expected HMM data files: {missing_files}")

        # Create the touched file if all expected files are present
        shell('touch {output.done}')
        shell('touch {output.done}')

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule for mapping PE reads to the genome with Bowtie2
rule chromLengths:
    input:
        par1 = PARENT_1_DNA
    output:
        chr_len = join(OUT_DIR, 'msg.chrLengths')
    log:
        join(OUT_DIR, 'Logs', 'chrLengths.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'chrLengths_benchmark.tsv')
    message:
        """--- Outputting chromosome lengths ."""
    threads:
        2
    resources:
        mem_mb=1000
    conda:
        'envs/DaGRP.yml'
    shell:
        'faidx {input.par1} -i chromsizes | tr "\t" "," > {output.chr_len}.tmp &&'
        ' echo "chr,length" | cat - {output.chr_len}.tmp > {output.chr_len} &&'
        ' rm {output.chr_len}.tmp'


##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule for mapping PE reads to the genome with Bowtie2
rule fit:  
    input:
        join(OUT_DIR, 'hmm_data', '{sample}', 'hmm.ok'),
        chr_len = join(OUT_DIR, 'msg.chrLengths')
    output:
        pdf = join(OUT_DIR, 'hmm_fit', '{sample}', '{sample}-hmmprob.pdf')
    params:
        sex = config['fit_hmm']['sex'],
        deltapar1 = config['fit_hmm']['deltapar1'],
        deltapar2 = config['fit_hmm']['deltapar2'],
        recRate = config['fit_hmm']['recRate'],
        rfac = config['fit_hmm']['rfac'],
        chroms = config['fit_hmm']['chroms'],
        sexchrom = config['fit_hmm']['sexchrom'],
        prior = config['fit_hmm']['prior'],
        theta = config['fit_hmm']['theta'],
        gff_thresh_conf = config['fit_hmm']['gff_thresh_conf'],
        one_site_per_contig = config['fit_hmm']['one_site_per_contig'],
        chroms2plot = config['fit_hmm']['chroms2plot'],
        pepthresh = config['fit_hmm']['pepthresh'],
        use_filter_hmmdata_pl = config['fit_hmm']['use_filter_hmmdata_pl']
    log:
        join(OUT_DIR, 'Logs', '{sample}', 'fit_hmm.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', '{sample}', 'fit_hmm_benchmark.tsv')
    message:
        """--- Fitting HMM for sample "{wildcards.sample}" ."""
    threads:
        8
    resources:
        mem_mb=32000
    run:
        shell('bash ' + join(SCRIPTS_DIR, 'run_fit_hmm.sh') +
                ' -o ' + join(OUT_DIR, 'hmm_data') +
                ' -R ' + join(OUT_DIR, 'hmm_fit') +
                ' -s {params.sex}' 
                ' -p {params.deltapar1}' 
                ' -q {params.deltapar2}' 
                ' -a {params.recRate}' 
                ' -r {params.rfac}' 
                ' -i {wildcards.sample}'
                ' -c {params.chroms}' 
                ' -x {params.sexchrom}' 
                ' -z {params.prior}' 
                ' -t {params.theta}' 
                ' -m {params.gff_thresh_conf}' 
                ' -u {params.one_site_per_contig}' 
                ' -y {params.chroms2plot}' 
                ' -j {params.pepthresh}' 
                ' -n ' + join(BASE_MSG) +
                ' -v {params.use_filter_hmmdata_pl}' 
                ' -l {input.chr_len}'
                ' > {log} 2>&1')

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule for mapping PE reads to the genome with Bowtie2
rule ancestry_probs:
    input:
        expand(join(OUT_DIR, 'hmm_fit', '{sample}', '{sample}-hmmprob.pdf'), sample = SAMPLES),
        chr_len = join(OUT_DIR, 'msg.chrLengths')
    output:
        anc1 = join(OUT_DIR, 'ancestry_data', 'ancestry-probs-par1.tsv'),
        anc2 = join(OUT_DIR, 'ancestry_data', 'ancestry-probs-par2.tsv')
    log:
        join(OUT_DIR, 'Logs', 'summary_plots.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'summary_plots_benchmark.tsv')
    message:
        """--- Outputting summary plots and ancestry probablities ."""
    threads:
        8
    resources:
        mem_mb=32000
    run:
        shell('bash ' + join(SCRIPTS_DIR, 'run_summary_plots.sh') +
                ' -c all'
                ' -d ' + join(OUT_DIR, 'hmm_fit') +
                ' -m ' + join(BASE_MSG) +
                ' -f 0.01'
                ' -p all'
                ' -n 0.03'
                ' -l {input.chr_len}'
                ' -t 1'
                ' > {log} 2>&1')
        shell('mv ancestry-probs-* ' + join(OUT_DIR, 'ancestry_data'))
        shell('mv offdiagonal_data.tsv rhat-offdiag.rda rlod-offdiag.rda ' + join(OUT_DIR, 'hmm_fit_images'))

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule for mapping PE reads to the genome with Bowtie2
rule pull_thin:
    input:
        anc1 = join(OUT_DIR, 'ancestry_data', 'ancestry-probs-par1.tsv'),
        anc2 = join(OUT_DIR, 'ancestry_data', 'ancestry-probs-par2.tsv')
    params:
        pheno = PHENO_FILE,
        sexchrom = config['fit_hmm']['sexchrom'],
        chroms = config['fit_hmm']['chroms'],
        diffac = config['fit_hmm']['diffac'],
        cross = config['fit_hmm']['cross'],
        sex = config['fit_hmm']['sex']
    output:
        ancestry2 = join(OUT_DIR, 'ancestry_data', 'ancestry-probs-par2.tsv.sorted.pulled.converted.thinned')
    log:
        join(OUT_DIR, 'Logs', 'pull_thin.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'pull_thin_benchmark.tsv')
    message:
        """--- Pull thin ."""
    threads:
        16
    resources:
        mem_mb=32000
    run:
        shell('bash ' + join(SCRIPTS_DIR, 'run_pull_thin.sh') +
                ' -c {params.chroms}'
                ' -x {params.sexchrom}'
                ' -p {input.anc1}'
                ' -q {input.anc2}'
                ' -f {params.diffac}'
                ' -k {params.cross}'
                ' -n {params.pheno}'
                ' -s {params.sex}'
                ' -t ' + join(OUT_DIR, 'ancestry_data', 'pt.cfg') +
                ' -m ' + join(BASE_MSG) +
                ' > {log} 2>&1')
        shell('mv {params.pheno}.sorted* ' + join(OUT_DIR, 'ancestry_data'))

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##
# __  __       _ _   _  ___   ____
#|  \/  |_   _| | |_(_)/ _ \ / ___|
#| |\/| | | | | | __| | | | | |
#| |  | | |_| | | |_| | |_| | |___
#|_|  |_|\__,_|_|\__|_|\__\_\\____|
#
##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## Rule to collate fastQC and Bowtie2 outputs with multiQC
rule multiQC:
    input:
        expand(join(OUT_DIR, 'bamqc', '{sample}', 'qualimapReport.html'), sample = SAMPLES),
        expand(join(OUT_DIR, 'fastQC', '{sample}.R1_fastqc.html'), sample = SAMPLES),
        expand(join(OUT_DIR, 'fastQC_trim', '{sample}.R1_fastqc.html'), sample = SAMPLES)
    output:
        file = join(OUT_DIR, 'MultiQC', 'multiqc_report.html')
    log:
        join(OUT_DIR, 'Logs', 'MultiQC', 'multiQC.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'MultiQC', 'multiQC.benchmark.tsv')
    message:
        """--- Running MultiQC """
    conda:
        'envs/DaGRP.yml'
    shell:
        'ls -1 ' + join(OUT_DIR) + '/bamqc/* | grep ":" | sed "s/://g" >> ' + join(OUT_DIR, 'MultiQC', 'summary_files.txt') +
        ' && ls -1 ' + join(OUT_DIR) + '/fastQC/*fastqc.zip >> ' + join(OUT_DIR, 'MultiQC', 'summary_files.txt') +
        ' && ls -1 ' + join(OUT_DIR) + '/fastQC_trim/*fastqc.zip >> ' + join(OUT_DIR, 'MultiQC', 'summary_files.txt') +  
        ' && multiqc'
                ' -f'
                ' -o ' + join(OUT_DIR, 'MultiQC') + ' -d -dd 1 -l ' + join(OUT_DIR, 'MultiQC', 'summary_files.txt') +
                ' > {log} 2>&1'
