"""
Author: Y. Ahmed-Braimah
--- Snakemake workflow for ATAC-seq analysis
"""

import json
import re
import os
import yaml
from os.path import join, basename, dirname, isfile
from os import getcwd, listdir
from subprocess import check_output
import subprocess
##--------------------------------------------------------------------------------------##
## Functions
##--------------------------------------------------------------------------------------##

# To print process messages
def message(x):
  print()

# To remove suffix from a string
def rstrip(text, suffix):
    if not text.endswith(suffix):
        return text
    return text[:len(text)-len(suffix)]


##--------------------------------------------------------------------------------------##
## Global config files:
##--------------------------------------------------------------------------------------##

configfile: 'config.yml'

DNA = config['DNA']
GTF = config['GTF']
MITO_ID = config['MITO_ID']
GROUPS = config['GROUPS']

# Full path to a folder where final output files will be deposited.
OUT_DIR = config['OUT_DIR']

# DNAseq Samples and their corresponding filenames.
# paired-end:
FILES = json.load(open(config['PE_SAMPLES_JSON']))
SAMPLES = sorted(FILES.keys())

## Create the final output directory if it doesn't already exist
if not os.path.exists(OUT_DIR):
            os.makedirs(OUT_DIR)

##--------------------------------------------------------------------------------------##
## RULES
##--------------------------------------------------------------------------------------##

rule all:
    input:
        join(OUT_DIR, 'MultiQC', 'multiqc_report.html'),
        expand(join(OUT_DIR, 'MACS', '{group}', 'finalPeakList.narrowPeak.gz'), group = GROUPS),
        join(OUT_DIR, 'MACS', 'peakCounts_MACS.counts.gz')

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##
#  ___   ____
# / _ \ / ___|
#| | | | |
#| |_| | |___
# \__\_\\____|
#
##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule fastqc:
    input:
        r1 = lambda wildcards: FILES[wildcards.sample]['R1'],
        r2 = lambda wildcards: FILES[wildcards.sample]['R2'],
    output:
        r1 = join(OUT_DIR, 'fastQC', '{sample}.R1_fastqc.html'),
        r2 = join(OUT_DIR, 'fastQC', '{sample}.R2_fastqc.html'),
    log:
        join(OUT_DIR, 'Logs', 'fastQC', '{sample}.fastQC.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'fastQC', '{sample}.fastQC.benchmark.tsv')
    message:
        """--- Checking read quality of sample "{wildcards.sample}" with FastQC """
    conda:
        'envs/atac_yablab.yml'
    shell:
        'fastqc'
            ' -o ' + join(OUT_DIR, 'fastQC') +
            ' -t 4'
            ' -q'
            ' {input.r1} {input.r2}'
            ' > {log} 2>&1'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule cutadapt:
    input:
        lambda wildcards: FILES[wildcards.sample]['R1'],
        lambda wildcards: FILES[wildcards.sample]['R2']
    output:
        fastq1 = join(OUT_DIR, 'trimmed_reads', '{sample}.1.fq.gz'),
        fastq2 = join(OUT_DIR, 'trimmed_reads', '{sample}.2.fq.gz'),
        qc = join(OUT_DIR, 'trimmed_reads', '{sample}.qc.txt')
    params:
        # https://cutadapt.readthedocs.io/en/stable/guide.html#adapter-types
        adapters="-a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -a CTGTCTCTTATACACATCT -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT -A CTGTCTCTTATACACATCT",
        # https://cutadapt.readthedocs.io/en/stable/guide.html#
        extra="--minimum-length 50 -q 20"
    log:
        join(OUT_DIR, 'Logs', 'cutadapt', '{sample}.cutadapt.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'cutadapt', '{sample}.cutadapt.benchmark.tsv')
    message:
        """--- Trimming adaptors for sample {wildcards.sample}."""
    threads:
        4
    resources:
        mem_mb=8000
    wrapper:
        "v3.10.2/bio/cutadapt/pe"

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule bowtie2_build:
    output:
        reference = join(OUT_DIR, 'reference', 'genome.fasta'),
        idx = join(OUT_DIR, 'reference', 'genome.rev.2.bt2')
    log:
        join(OUT_DIR, 'Logs', 'Bowtie2', 'bowtie2-build.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'Bowtie2', 'bt2-build.benchmark.tsv')
    threads: 
        8
    shell:
        ' cp ' + DNA + ' ' + join(OUT_DIR, 'reference', 'genome.fasta') +
        ' && bowtie2-build'
            ' {output.reference} ' +
            join(OUT_DIR, 'reference', 'genome') +
            ' > {log} 2>&1'


##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule Bowtie2:
    input:
        r1 = join(OUT_DIR, 'trimmed_reads', '{sample}.1.fq.gz'),
        r2 = join(OUT_DIR, 'trimmed_reads', '{sample}.2.fq.gz'),
        idx = join(OUT_DIR, 'reference', 'genome.rev.2.bt2')
    output:
        cbam = join(OUT_DIR, 'Bowtie2', '{sample}.csorted.bowtie2.bam'),
        nbam = join(OUT_DIR, 'Bowtie2', '{sample}.nsorted.bowtie2.bam')
        
    threads:
        8
    resources:
        mem_mb=16000
    log:
        bt2 = join(OUT_DIR, 'Logs', 'Bowtie2', '{sample}.bowtie2.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'Bowtie2', '{sample}.benchmark.tsv')
    message:
        """--- Mapping PE sample "{wildcards.sample}" with Bowtie2."""
    conda:
        'envs/atac_yablab.yml'
    shell:
        '(bowtie2'
                ' --mm'
                ' -p 8'
                ' --local'
                ' --maxins 2000'
                ' --rg-id i{wildcards.sample}'
                ' --rg SM:{wildcards.sample}'
                ' -x ' + join(OUT_DIR, 'reference', 'genome') +
                ' -1 {input.r1}'
                ' -2 {input.r2}'
                ') 2> {log.bt2}'
                ' | samtools sort -n -@ 8 -o {output.nbam} -'
        ' && samtools sort --threads 8 -o {output.cbam} {output.nbam}'
        ' && samtools index -@ 4 {output.cbam}'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule qualimap:
    input:
        bam = join(OUT_DIR, 'Bowtie2', '{sample}.csorted.bowtie2.bam'),
    output:
        bamqc = join(OUT_DIR, 'Bowtie2', '{sample}', 'bamqc', 'qualimapReport.html')
    log:
        bamqc = join(OUT_DIR, 'Logs', 'Qualimap', '{sample}.bamqc.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'Qualimap', '{sample}.benchmark.tsv')
    message:
        """--- Running BAMQC for sample "{wildcards.sample}"."""
    threads:
        8
    resources:
        mem_mb=32000
    conda:
        'envs/atac_yablab.yml'
    shell:
        'qualimap bamqc'
            ' -bam {input.bam}'
            ' -c'
            ' -outdir ' + join(OUT_DIR, 'Bowtie2', '{wildcards.sample}', 'bamqc') +
            ' --java-mem-size=32G'
            ' -nt 8'
            ' > {log.bamqc} 2>&1'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule bamMarkDuplicates:
    input:
        cbam = join(OUT_DIR, 'Bowtie2', '{sample}.csorted.bowtie2.bam')
    output:
        dupremoC = join(OUT_DIR, 'Bowtie2', '{sample}.csorted_filt.noDupl.bam'),
        dupremoN = join(OUT_DIR, 'Bowtie2', '{sample}.nsorted_filt.noDupl.bam'),
        idxstats = join(OUT_DIR, 'Bowtie2', '{sample}.idxstats'),
        flagstat = join(OUT_DIR, 'Bowtie2', '{sample}.flagstat')
    threads:
        4
    resources:
        mem_mb=8000
    log:
        join(OUT_DIR, 'Logs', 'Bowtie2', '{sample}.dupmark.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'Bowtie2', '{sample}.dupmark.benchmark.tsv')
    message:
        """--- Marking duplicates for "{wildcards.sample}" with Picard."""
    conda:
        'envs/atac_yablab.yml'
    shell:
        'samtools view'
                ' -F 1804'
                ' -f 2'
                ' -q 30'
                ' -u {input.cbam}'
                ' | samtools sort -@ 8 -n /dev/stdin'
                ' -o {wildcards.sample}.csorted_tmp1_filt.bam'
        ' && samtools fixmate'
                ' -r {wildcards.sample}.csorted_tmp1_filt.bam'
                ' {wildcards.sample}.csorted_tmp2_filt.bam'
        ' && samtools view '
                ' -F 1804'
                ' -f 2'
                ' -u {wildcards.sample}.csorted_tmp2_filt.bam'
                ' | samtools sort -@ 8 -o {wildcards.sample}.csorted_filt.bam -'
        ' && picard MarkDuplicates'
                ' I={wildcards.sample}.csorted_filt.bam'
                ' O={wildcards.sample}.csorted_filt.dupmark.bam'
                ' M={log}'
                ' VALIDATION_STRINGENCY=LENIENT'
                ' ASSUME_SORTED=true'
                ' REMOVE_DUPLICATES=false'
        ' && samtools view '
                ' -F 1804'
                ' -f 2'
                ' -b'
                ' {wildcards.sample}.csorted_filt.dupmark.bam'
                ' | samtools sort -@ 8 -o {output.dupremoC} -'
        ' && samtools sort -n -@ 8 -o {output.dupremoN} {output.dupremoC}'
        ' && rm {wildcards.sample}.csorted_tmp1_filt.bam'
                ' {wildcards.sample}.csorted_tmp2_filt.bam'
                ' {wildcards.sample}.csorted_filt.bam'
                ' {wildcards.sample}.csorted_filt.dupmark.bam'
        ' && samtools index -@ 4 {output.dupremoC}'
        ' && samtools idxstats {output.dupremoC} > {output.idxstats}'
        ' && samtools flagstat -@ 4 {output.dupremoC} > {output.flagstat}'

        ##### Still need to include library complexity procedure
        ##### from ENCODE protocol
        ##### Also right stderr or log file

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

## TODO!: Add subsampling later
rule Bam_to_tagAlign:
    input:
        dupremoN = join(OUT_DIR, 'Bowtie2', '{sample}.nsorted_filt.noDupl.bam')
    # params:
    #     mt = MITO_ID
    output:
        tagAln = join(OUT_DIR, 'Bowtie2', '{sample}.tagAlign.gz'),
        tagAlnTn5 = join(OUT_DIR, 'Bowtie2', '{sample}.tn5.tagAlign.gz'),
        BEDpe = join(OUT_DIR, 'Bowtie2', '{sample}.bedpe.gz')
    threads:
        4
    resources:
        mem_mb=8000
    log:
        join(OUT_DIR, 'Logs', 'Bowtie2', '{sample}.tagAlign.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'Bowtie2', '{sample}.tagAlign.benchmark.tsv')
    message:
        """--- Converting BAM to tagAlign for "{wildcards.sample}"."""
    conda:
        'envs/atac_yablab.yml'
    shell:
        'bedtools bamtobed'
                ' -bedpe'
                ' -mate1'
                ' -i {input.dupremoN}'
                ' | gzip -nc'
                ' > {output.BEDpe}'
        ' && zcat {output.BEDpe}'
                ' | awk \'BEGIN{{OFS="\t"}}{{printf $1"\t"$2"\t"$3"\tN\t1000\t"$9"\\n"$4"\t"$5"\t"$6"\tN\t1000\t"$10"\\n"}}\' '
                ' | gzip -nc'
                ' > {output.tagAln}'
        ' && zcat {output.tagAln}'
                ' | awk -F $"\t" \'BEGIN {{OFS = FS}}{{ if ($6 == "+") {{$2 = $2 + 4}} else if ($6 == "-") {{$3 = $3 - 5}} print $0}}\''
                ' | gzip -nc'
                ' > {output.tagAlnTn5}'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule selfPseudoRep:
    input:
        tagAln = join(OUT_DIR, 'Bowtie2', '{sample}.tagAlign.gz')
    output:
        tagAln1 = join(OUT_DIR, 'Bowtie2', '{sample}.PE2SE.pr1.tagAlign.gz'),
        tagAln2 = join(OUT_DIR, 'Bowtie2', '{sample}.PE2SE.pr2.tagAlign.gz')
    threads:
        4
    resources:
        mem_mb=8000
    log:
        join(OUT_DIR, 'Logs', 'Bowtie2', '{sample}.selfPseudoRep.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'Bowtie2', '{sample}.selfPseudoRep.benchmark.tsv')
    message:
        """--- Generate self-pseudoreplicates for each replicate "{wildcards.sample}"."""
    conda:
        'envs/atac_yablab.yml'
    shell:
        'zcat {input.tagAln}'
                ' | sed "N;s/\\n/\\t/"'
                ' | gzip -nc'
                ' > {wildcards.sample}.temp.bedpe.gz'
        ' && nlines=$( zcat {wildcards.sample}.temp.bedpe.gz | wc -l)'
                ' && nlines=$(( (nlines + 1) / 2 ))'
                ' && zcat -f {wildcards.sample}.temp.bedpe.gz'
                ' | shuf --random-source=<(openssl enc -aes-256-ctr -pass pass:$(zcat -f {input.tagAln} | wc -c) -nosalt </dev/zero 2>/dev/null) '
                ' | split -d -l $nlines - {wildcards.sample}.filt.nodup.'
        ' && awk \'BEGIN{{OFS="\t"}}{{printf $1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$6"\\n"$7"\t"$8"\t"$9"\t"$10"\t"$11"\t"$12"\\n"}}\' {wildcards.sample}.filt.nodup.00  '
                ' | gzip -nc'
                ' > {output.tagAln1}'
        ' && awk \'BEGIN{{OFS="\t"}}{{printf $1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$6"\\n"$7"\t"$8"\t"$9"\t"$10"\t"$11"\t"$12"\\n"}}\' {wildcards.sample}.filt.nodup.01  '
                ' | gzip -nc'
                ' > {output.tagAln2}'
        ' && rm {wildcards.sample}.filt.nodup.00 {wildcards.sample}.filt.nodup.01 {wildcards.sample}.temp.bedpe.gz'


##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule allPseudoRep:
    input:
        tagAlign = lambda wildcards: expand(join(OUT_DIR, 'Bowtie2', '{sample}.tagAlign.gz'), sample=GROUPS[wildcards.group]),
        pr1 = lambda wildcards: expand(join(OUT_DIR, 'Bowtie2', '{sample}.PE2SE.pr1.tagAlign.gz'), sample=GROUPS[wildcards.group]),
        pr2 = lambda wildcards: expand(join(OUT_DIR, 'Bowtie2', '{sample}.PE2SE.pr2.tagAlign.gz'), sample=GROUPS[wildcards.group])
    output:
        tagAln_pool = join(OUT_DIR, 'Bowtie2', '{group}', '{group}.Rep0.tagAlign.gz'),
        tagAlnTn5_pool = join(OUT_DIR, 'Bowtie2', '{group}', '{group}.Rep0.tn5.tagAlign.gz'),
        pr1_pool = join(OUT_DIR, 'Bowtie2', '{group}', '{group}.Rep0.pr1.tagAlign.gz'),
        pr2_pool = join(OUT_DIR, 'Bowtie2', '{group}', '{group}.Rep0.pr2.tagAlign.gz')
    threads:
        4
    resources:
        mem_mb=8000
    log:
        join(OUT_DIR, 'Logs', 'Bowtie2', '{group}', '{group}.tagAlign.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'Bowtie2', '{group}', '{group}.tagAlign.benchmark.tsv')
    message:
        """--- Generate pooled dataset and pooled-pseudoreplicates for "{wildcards.group}" """
    conda:
        'envs/atac_yablab.yml'
    shell:
        'zcat {input.tagAlign} | gzip -nc > {output.tagAln_pool}'
        ' && zcat {input.pr1} | gzip -nc > {output.pr1_pool}'
        ' && zcat {input.pr2} | gzip -nc > {output.pr2_pool}'
        ' && zcat {output.tagAln_pool}'
                ' | awk -F $"\t" \'BEGIN {{OFS = FS}}{{ if ($6 == "+") {{$2 = $2 + 4}} else if ($6 == "-") {{$3 = $3 - 5}} print $0}}\''
                ' | gzip -nc'
                ' > {output.tagAlnTn5_pool}'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule FragLen_stats:
    input:
        dupremoC = join(OUT_DIR, 'Bowtie2', '{sample}.csorted_filt.noDupl.bam')
    output:
        fraglen_stat = join(OUT_DIR, 'Bowtie2', '{sample}.insert_size_metrics.txt'),
        fraglen_plot = join(OUT_DIR, 'Bowtie2', '{sample}.insert_size_histogram.pdf')
    threads:
        4
    resources:
        mem_mb=8000
    log:
        join(OUT_DIR, 'Logs', 'Bowtie2', '{sample}.fraglen.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'Bowtie2', '{sample}.fraglen.benchmark.tsv')
    message:
        """--- Generating fragment length statistics for "{wildcards.sample}". """
    conda:
        'envs/atac_yablab.yml'
    shell:
        'picard CollectInsertSizeMetrics'
                ' I={input.dupremoC}'
                ' O={output.fraglen_stat}'
                ' H={output.fraglen_plot}'
                ' W=1000'
                ' VERBOSITY=ERROR'
                ' QUIET=TRUE'
                ' STOP_AFTER=5000000'
                ' USE_JDK_DEFLATER=TRUE'
                ' USE_JDK_INFLATER=TRUE'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule compute_genome_size:
    input:
        reference = join(OUT_DIR, 'reference', 'genome.fasta')
    output:
        cs = join(OUT_DIR, 'reference', 'chrom_sizes.txt'),
        fai = join(OUT_DIR, 'reference', 'genome.fasta.fai')
    conda:
        'envs/atac_yablab.yml'
    shell:
        'samtools faidx {input.reference}'
        ' && cut -f1,2 {output.fai} > {output.cs}'



##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule MACS_track:
    input:
        tag = join(OUT_DIR, 'Bowtie2', '{sample}.tagAlign.gz'),
        ginfo = join(OUT_DIR, 'reference', 'chrom_sizes.txt')
    output:
        peaks = join(OUT_DIR, 'MACS', '{sample}', '{sample}_peaks.narrowPeak'),
        peaks_sub = join(OUT_DIR, 'MACS', '{sample}', '{sample}.narrowPeak.gz'),
        bigwig_fc = join(OUT_DIR, 'MACS', '{sample}', '{sample}_sig.fc.signal.bigwig'),
        bigwig_pval = join(OUT_DIR, 'MACS', '{sample}', '{sample}_sig.pval.signal.bigwig')
    threads:
        1
    resources:
        mem_mb=32000
    log:
        join(OUT_DIR, 'Logs', 'MACS', '{sample}', '{sample}.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'MACS', '{sample}', '{sample}.tsv')
    message:
        """--- Call peaks for "{wildcards.sample}" samples with MACS"""
    conda:
        'envs/atac_yablab.yml'
    shell:
        'gsize=$(awk \'BEGIN{{sum=0}} {{sum+=$2}} END{{print sum}}\' {input.ginfo})'
        ' && macs3 callpeak'
            ' -g $gsize'
            ' -f BED'
            ' --nomodel'
            ' --keep-dup all'
            ' -p 0.01'
            ' --shift -75'
            ' --extsize 150'
            ' --keep-dup all'
            ' --call-summits'
            ' -B'
            ' --SPMR'
            ' --outdir ' + join(OUT_DIR, 'MACS', '{wildcards.sample}') +
            ' -n {wildcards.sample}'
            ' -t {input.tag}'
            ' > {log} 2>&1'
        ' && sort -k 8gr,8gr ' + join(OUT_DIR, 'MACS', '{wildcards.sample}', '{wildcards.sample}_peaks.narrowPeak') +
            ' | awk \'BEGIN{{OFS="\t"}}{{$4="Peak_"NR; if ($2<0) $2=0; if ($3<0) $3=0; if ($10==-1) $10=$2+int(($3-$2+1)/2.0); print $0}}\''
            ' | head -n 300000'
            ' | gzip -nc'
            ' > {output.peaks_sub}'
        ' && macs3 bdgcmp'
            ' -t ' + join(OUT_DIR, 'MACS', '{wildcards.sample}', '{wildcards.sample}_treat_pileup.bdg') +
            ' -c ' + join(OUT_DIR, 'MACS', '{wildcards.sample}', '{wildcards.sample}_control_lambda.bdg') +
            ' --o-prefix {wildcards.sample}'
            ' -m FE'
        ' && slopBed'
            ' -i {wildcards.sample}_FE.bdg'
            ' -g {input.ginfo}'
            ' -b 0'
            ' | bedClip stdin {input.ginfo} {wildcards.sample}.fc.signal.bedgraph'
        ' && sort -k1,1 -k2,2n {wildcards.sample}.fc.signal.bedgraph'
            ' | awk \'BEGIN{{OFS="\\t"}}{{if (NR==1 || NR>1 && (prev_chr!=$1 || prev_chr==$1 && prev_chr_e<=$2)) {{print $0}}; prev_chr=$1; prev_chr_e=$3;}}\''
            ' > {wildcards.sample}.fc.signal.bedgraph_srt'
        ' && bedGraphToBigWig'
            ' {wildcards.sample}.fc.signal.bedgraph_srt'
            ' {input.ginfo}'
            ' {output.bigwig_fc}'
        ' && sval=$(zcat -f {input.tag} | wc -l | awk \'{{printf $1/1000000}}\')'
            ' && macs3 bdgcmp'
            ' -t ' + join(OUT_DIR, 'MACS', '{wildcards.sample}', '{wildcards.sample}_treat_pileup.bdg') +
            ' -c ' + join(OUT_DIR, 'MACS', '{wildcards.sample}', '{wildcards.sample}_control_lambda.bdg') +
            ' --o-prefix {wildcards.sample}'
            ' -m ppois'
            ' -S $sval'
        ' && slopBed'
            ' -i {wildcards.sample}_ppois.bdg'
            ' -g {input.ginfo}'
            ' -b 0'
            ' | bedClip stdin {input.ginfo} {wildcards.sample}.pval.signal.bedgraph'
        ' && sort -k1,1 -k2,2n {wildcards.sample}.pval.signal.bedgraph'
            ' | awk \'BEGIN{{OFS="\\t"}}{{if (NR==1 || NR>1 && (prev_chr!=$1 || prev_chr==$1 && prev_chr_e<=$2)) {{print $0}}; prev_chr=$1; prev_chr_e=$3;}}\''
            ' > {wildcards.sample}.pval.signal.bedgraph_srt'
        ' && bedGraphToBigWig'
            ' {wildcards.sample}.pval.signal.bedgraph_srt'
            ' {input.ginfo}'
            ' {output.bigwig_pval}'
        ' && rm ' + join(OUT_DIR, 'MACS', '{wildcards.sample}', '{wildcards.sample}_*.bdg') +
            ' ' + join(OUT_DIR, 'MACS', '{wildcards.sample}', '{wildcards.sample}_summits.bed') +
            ' {wildcards.sample}_FE.bdg'
            ' {wildcards.sample}.fc.signal.bedgraph*'
            ' {wildcards.sample}_ppois.bdg'
            ' {wildcards.sample}.pval.signal.bedgraph*'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule MACS_pool:
    input:
        tagAln_pool = join(OUT_DIR, 'Bowtie2', '{group}', '{group}.Rep0.tagAlign.gz'),
        ginfo = join(OUT_DIR, 'reference', 'chrom_sizes.txt')
    output:
        peaks = join(OUT_DIR, 'MACS', '{group}', '{group}_peaks.narrowPeak'),
        peaks_sub = join(OUT_DIR, 'MACS', '{group}', '{group}.pool.narrowPeak.gz'),
        bigwig_fc = join(OUT_DIR, 'MACS', '{group}', '{group}_sig.fc.signal.bigwig'),
        bigwig_pval = join(OUT_DIR, 'MACS', '{group}', '{group}_sig.pval.signal.bigwig')
    threads:
        1
    resources:
        mem_mb=32000
    log:
        join(OUT_DIR, 'Logs', 'MACS', '{group}', '{group}.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'MACS', '{group}', '{group}.tsv')
    message:
        """--- Call peaks for "{wildcards.group}" samples with MACS"""
    conda:
        'envs/atac_yablab.yml'
    shell:
        'gsize=$(awk \'BEGIN{{sum=0}} {{sum+=$2}} END{{print sum}}\' {input.ginfo})'
        ' && macs3 callpeak'
            ' -g $gsize'
            ' -f BED'
            ' --nomodel'
            ' --keep-dup all'
            ' -p 0.01'
            ' --shift -75'
            ' --extsize 150'
            ' --call-summits'
            ' -B'
            ' --SPMR'
            ' --outdir ' + join(OUT_DIR, 'MACS', '{wildcards.group}') +
            ' -n {wildcards.group}'
            ' -t {input.tagAln_pool}'
            ' > {log} 2>&1'
        ' && sort -k 8gr,8gr ' + join(OUT_DIR, 'MACS', '{wildcards.group}', '{wildcards.group}_peaks.narrowPeak') +
            ' | awk \'BEGIN{{OFS="\t"}}{{$4="Peak_"NR; if ($2<0) $2=0; if ($3<0) $3=0; if ($10==-1) $10=$2+int(($3-$2+1)/2.0); print $0}}\''
            ' | head -n 300000'
            ' | gzip -nc'
            ' > {output.peaks_sub}'
        ' && macs3 bdgcmp'
            ' -t ' + join(OUT_DIR, 'MACS', '{wildcards.group}', '{wildcards.group}_treat_pileup.bdg') +
            ' -c ' + join(OUT_DIR, 'MACS', '{wildcards.group}', '{wildcards.group}_control_lambda.bdg') +
            ' --o-prefix {wildcards.group}'
            ' -m FE'
        ' && slopBed'
            ' -i {wildcards.group}_FE.bdg'
            ' -g {input.ginfo}'
            ' -b 0'
            ' | bedClip stdin {input.ginfo} {wildcards.group}.fc.signal.bedgraph'
        ' && sort -k1,1 -k2,2n {wildcards.group}.fc.signal.bedgraph'
            ' | awk \'BEGIN{{OFS="\\t"}}{{if (NR==1 || NR>1 && (prev_chr!=$1 || prev_chr==$1 && prev_chr_e<=$2)) {{print $0}}; prev_chr=$1; prev_chr_e=$3;}}\''
            ' > {wildcards.group}.fc.signal.bedgraph_srt'
        ' && bedGraphToBigWig'
            ' {wildcards.group}.fc.signal.bedgraph_srt'
            ' {input.ginfo}'
            ' {output.bigwig_fc}'
        ' && sval=$(zcat -f {input.tagAln_pool} | wc -l | awk \'{{printf $1/1000000}}\')'
            ' && macs3 bdgcmp'
            ' -t ' + join(OUT_DIR, 'MACS', '{wildcards.group}', '{wildcards.group}_treat_pileup.bdg') +
            ' -c ' + join(OUT_DIR, 'MACS', '{wildcards.group}', '{wildcards.group}_control_lambda.bdg') +
            ' --o-prefix {wildcards.group}'
            ' -m ppois'
            ' -S $sval'
        ' && slopBed'
            ' -i {wildcards.group}_ppois.bdg'
            ' -g {input.ginfo}'
            ' -b 0'
            ' | bedClip stdin {input.ginfo} {wildcards.group}.pval.signal.bedgraph'
        ' && sort -k1,1 -k2,2n {wildcards.group}.pval.signal.bedgraph'
            ' | awk \'BEGIN{{OFS="\\t"}}{{if (NR==1 || NR>1 && (prev_chr!=$1 || prev_chr==$1 && prev_chr_e<=$2)) {{print $0}}; prev_chr=$1; prev_chr_e=$3;}}\''
            ' > {wildcards.group}.pval.signal.bedgraph_srt'
        ' && bedGraphToBigWig'
            ' {wildcards.group}.pval.signal.bedgraph_srt'
            ' {input.ginfo}'
            ' {output.bigwig_pval}'
        ' && rm ' + join(OUT_DIR, 'MACS', '{wildcards.group}', '{wildcards.group}_*.bdg') +
            ' ' + join(OUT_DIR, 'MACS', '{wildcards.group}', '{wildcards.group}_summits.bed') +
            ' {wildcards.group}_FE.bdg'
            ' {wildcards.group}.fc.signal.bedgraph*'
            ' {wildcards.group}_ppois.bdg'
            ' {wildcards.group}.pval.signal.bedgraph*'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

def generate_intersect_command(wildcards):
    group = wildcards.group
    reps = GROUPS[group]
    pooled_file = os.path.join(OUT_DIR, 'MACS', group, group + '.pool.narrowPeak.gz')

    cmd = (
        "intersectBed -wo -a {pooled_file} -b {rep_file} | awk 'BEGIN{{FS=\"\\t\";OFS=\"\\t\"}}{{s1=$3-$2; s2=$13-$12; if (($21/s1 >= 0.5) || ($21/s2 >= 0.5)) {{print $0}}}}' | cut -f 1-10 | sort | uniq"
        .format(pooled_file=pooled_file, rep_file=os.path.join(OUT_DIR, 'MACS', reps[0], reps[0] + '.narrowPeak.gz'))
    )
    for rep in reps[1:]:
        rep_file = os.path.join(OUT_DIR, 'MACS', rep, rep + '.narrowPeak.gz')
        cmd += (
            " | intersectBed -wo -a stdin -b {rep_file} | awk 'BEGIN{{FS=\"\\t\";OFS=\"\\t\"}}{{s1=$3-$2; s2=$13-$12; if (($21/s1 >= 0.5) || ($21/s2 >= 0.5)) {{print $0}}}}' | cut -f 1-10 | sort | uniq"
            .format(rep_file=rep_file)
        )

    final_output = os.path.join(OUT_DIR, 'MACS', group, 'finalPeakList.narrowPeak.gz')
    cmd += " | gzip -nc > {final_output}".format(final_output=final_output)
    
    return cmd




rule naive_overlap:
    input:
        peaks_group = join(OUT_DIR, 'MACS', '{group}', '{group}.pool.narrowPeak.gz'),
        peaks_sample = lambda wildcards: expand(join(OUT_DIR, 'MACS', '{sample}', '{sample}.narrowPeak.gz'), sample=GROUPS[wildcards.group])
    output:
        counts = join(OUT_DIR, 'MACS', '{group}', 'finalPeakList.narrowPeak.gz')
    params:
        intersect_cmd=lambda wildcards: generate_intersect_command(wildcards)
    threads:
        4
    resources:
        mem_mb=16000
    log:
        join(OUT_DIR, 'Logs', 'MACS', '{group}', 'naiveOverlap.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'MACS', '{group}', 'naiveOverlap.tsv')
    message:
        """--- Extracting overlapping peaks for sample "{wildcards.group}". """
    conda:
        'envs/atac_yablab.yml'
    shell:
        "{params.intersect_cmd}"


##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule BAM_stats_Alfred:
    input:
        dupremo = join(OUT_DIR, 'Bowtie2', '{sample}.csorted_filt.noDupl.bam'),
        promoters = join(OUT_DIR, 'reference', 'genome.bed')
    params:
        dna = DNA
    output:
        al_qc_tsv = join(OUT_DIR, 'Alfred', '{sample}.bamStats.unfiltered.tsv.gz'),
        al_qc_json = join(OUT_DIR, 'Alfred', '{sample}.bamStats.unfiltered.json.gz'),
        fbam = join(OUT_DIR, 'Bowtie2', '{sample}.final.bam'),
        al_qc_tsv_p = join(OUT_DIR, 'Alfred', '{sample}.bamStats.promoters.tsv.gz'),
        al_qc_json_p = join(OUT_DIR, 'Alfred', '{sample}.bamStats.promoters.json.gz')
    threads:
        4
    resources:
        mem_mb=8000
    log:
        join(OUT_DIR, 'Logs', 'Alfred', '{sample}.al_qc.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'Alfred', '{sample}.al_qc.benchmark.tsv')
    message:
        """--- Running stats on unfilter BAM of "{wildcards.sample}" with Alfred."""
    conda:
        'envs/atac_yablab.yml'
    shell:
        'alfred qc'
                ' -b {input.promoters}'
                ' -r {params.dna}'
                ' -o {output.al_qc_tsv}'
                ' -j {output.al_qc_json}'
                ' {input.dupremo}'
        ' && CHRS=`cat {input.promoters} | cut -f 1 | sort -k1,1V -k2,2n | uniq | tr \'\n\' \' \'`'
                ' && samtools view'
                ' -@ 4'
                ' -q 30'
                ' -b {input.dupremo}'
                ' $CHRS'
                ' > {output.fbam}'
        ' && samtools index -@ 4 {output.fbam}'
        ' && alfred qc'
                ' -b {input.promoters}'
                ' -r {params.dna}'
                ' -o {output.al_qc_tsv_p}'
                ' -j {output.al_qc_json_p}'
                ' {output.fbam}'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule extract_promoters:
    input:
        gtf = GTF
    output:
        bed = join(OUT_DIR, 'reference', 'genome.bed')
    params:
        up=config["promoter"]["upstream"],
        down=config["promoter"]["downstream"]
    shell: 
        'cat {input.gtf} | awk \'OFS="\\t" {{if ($3=="transcript") {{if ($7 == "+") {{print $1,$4-100,$4,$12,".",$7}} else {{print $1,$5-100,$5,$12,".",$7}}}}}}\' | tr -d \'";\' | sort -k1,1V -k2,2n > {output.bed}'


##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule peakCounts_MACS:
    input:
        peaks = expand(join(OUT_DIR, 'MACS', '{group}', 'finalPeakList.narrowPeak.gz'), group = GROUPS),
        fbam = expand(join(OUT_DIR, 'Bowtie2', '{sample}.csorted_filt.noDupl.bam'), sample = SAMPLES),
        tss = join(OUT_DIR, 'reference', 'genome.bed')
    output:
        counts = join(OUT_DIR, 'MACS', 'peakCounts_MACS.counts.gz')
    threads:
        4
    resources:
        mem_mb=16000
    log:
        join(OUT_DIR, 'Logs', 'MACS', 'peakCounts.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'MACS', 'peakCounts.tsv')
    message:
        """--- Extracting peak counts for MACS peaks."""
    conda:
        'envs/atac_yablab.yml'
    shell:
        'ls -1 ' + join(OUT_DIR, 'MACS', '*', 'finalPeakList.narrowPeak.gz') + ' > macs_peaks.list'
        ' && ls -1 ' + join(OUT_DIR, 'Bowtie2', '*.csorted_filt.noDupl.bam') + ' > macs_bams.list'
        ' && scripts/count.sh'
                ' {input.tss}'
                ' macs_peaks.list'
                ' macs_bams.list'
                ' peakCounts_MACS'
                ' > {log} 2>&1'
        ' && mv peakCounts_MACS* ' + join(OUT_DIR, 'MACS') +
        ' && rm macs_peaks.list macs_bams.list'

##--------------------------------------------------------------------------------------##
##--------------------------------------------------------------------------------------##

rule multiQC:
    input:
        expand(join(OUT_DIR, 'Bowtie2', '{sample}.csorted.bowtie2.bam'), sample = SAMPLES),
        expand(join(OUT_DIR, 'Bowtie2', '{sample}', 'bamqc', 'qualimapReport.html'), sample = SAMPLES),
        expand(join(OUT_DIR, 'Bowtie2', '{sample}.insert_size_metrics.txt'), sample = SAMPLES),
        expand(join(OUT_DIR, 'fastQC', '{sample}.R2_fastqc.html'), sample = SAMPLES),
        expand(join(OUT_DIR, 'trimmed_reads', '{sample}.2.fq.gz'), sample = SAMPLES),
        expand(join(OUT_DIR, 'MACS', '{sample}', '{sample}_peaks.narrowPeak'), sample = SAMPLES),
        expand(join(OUT_DIR, 'MACS', '{group}', '{group}.pool.narrowPeak.gz'), group = GROUPS)
        # expand(join(OUT_DIR, 'Alfred', '{sample}.bamStats.promoters.tsv.gz'), sample = SAMPLES)
    output:
        file = join(OUT_DIR, 'MultiQC', 'multiqc_report.html')
    log:
        join(OUT_DIR, 'Logs', 'MultiQC', 'multiQC.log')
    benchmark:
        join(OUT_DIR, 'Benchmarks', 'MultiQC', 'multiQC.benchmark.tsv')
    message:
        """--- Running MultiQC """
    conda:
        'envs/atac_yablab.yml'
    shell:
        'ls -1 ' + join(OUT_DIR) + '/Logs/Bowtie2/*.bowtie2.log > ' + join(OUT_DIR, 'MultiQC', 'summary_files.txt') +
        ' && ls -1 ' + join(OUT_DIR) + '/Bowtie2/*/bamqc | grep ":" | sed "s/://g" >> ' + join(OUT_DIR, 'MultiQC', 'summary_files.txt') +
        ' && ls -1 ' + join(OUT_DIR) + '/trimmed_reads/*.qc.txt >> ' + join(OUT_DIR, 'MultiQC', 'summary_files.txt') +
        ' && ls -1 ' + join(OUT_DIR) + '/fastQC/*fastqc.zip >> ' + join(OUT_DIR, 'MultiQC', 'summary_files.txt') +
        ' && ls -1 ' + join(OUT_DIR) + '/MACS/*/*xls >> ' + join(OUT_DIR, 'MultiQC', 'summary_files.txt') +
        ' && multiqc'
                ' -f'
                ' -o ' + join(OUT_DIR, 'MultiQC') + ' -d -dd 3 -l ' + join(OUT_DIR, 'MultiQC', 'summary_files.txt') +
                ' > {log} 2>&1'
